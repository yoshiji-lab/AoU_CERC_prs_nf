nextflow.enable.dsl = 2

/*
 * ============================================================
 * PRS Nextflow pipeline (LOCAL-only; safe for shared AoU buckets)
 * ============================================================
 *
 * This config intentionally avoids Google Batch + gs:// workdirs.
 * The pipeline assumes you have already copied:
 *   - pgen/pvar/psam locally (e.g., via gsutil cp)
 *   - weight files locally
 *
 * You can still point inputs to gs:// paths if you want, but the
 * defaults are local to avoid overwriting shared GCS workspaces.
 */

params {

  /*
   * -----------------
   * INPUTS (LOCAL)
   * -----------------
   */

  // Weight files (one per trait). Used to derive trait names from filenames.
  // Example: /workspaces/allofusgwasonmetabolictraits/urvashi_analysis/inputs/test/*.tsv.gz
  weights_glob = '/home/jupyter/workspaces/allofusgwasonmetabolictraits/urvashi_analysis/inputs/test/*.tsv.gz'

  // Optional: only score specific traits (comma-separated)
  // Example: traits = 'VATadj,BMIadj'
  traits = null

  // PGEN dataset directory (local path)
  // Must contain: <pfile_pref with chrom substituted>.pgen/.pvar/.psam
  pfile_dir  = '/home/jupyter/workspaces/allofusgwasonmetabolictraits/urvashi_analysis/pgen_dir'
  pfile_pref = 'snpqc.chr{chrom}'

  // Chromosomes to run (for your first test, keep 21..22)
  chroms = (1..22)

  /*
   * -----------------
   * OUTPUTS (LOCAL)
   * -----------------
   */

  outdir  = '/home/jupyter/workspaces/allofusgwasonmetabolictraits/urvashi_analysis/prs_out_chr1_22_test_v1'
  workdir = '/home/jupyter/workspaces/allofusgwasonmetabolictraits/urvashi_analysis/nf_work/prs_nf_test_v1'

  // Max simultaneous chromosome-jobs (local VM)
  max_forks = 2

  /*
   * -----------------
   * BEHAVIOR
   * -----------------
   */
  allow_strand_flip   = false
  write_list_variants = false

  /*
   * -----------------
   * TOOLS
   * -----------------
   */
  plink2_bin = 'plink2'
}

workDir = params.workdir

process {
  executor = 'local'

  // Keep bash strict mode everywhere
  shell = ['/bin/bash', '-euo', 'pipefail']

  // Avoid copying huge .pgen files into each task dir
  stageInMode = 'symlink'

  // Default resources (override per-process below)
  cpus   = 8
  memory = '16 GB'

  // Concurrency control on ONE VM
  maxForks = params.max_forks

  withName: SCORE_CHR_ALL_TRAITS {
    cpus   = 8
    memory = '16 GB'
    maxForks = params.max_forks ?: 2
  }

  withName: MERGE_TRAIT {
    cpus = 4
    memory = '16 GB'
    maxForks = 4
  }

  withName: BUILD_MATRIX {
    cpus = 4
    memory = '32 GB'
  }
}

/*
 * =========================
 * OPTIONAL: NEXTFLOW REPORTS
 * =========================
 */
trace {
  enabled = true
  file = "${params.outdir}/pipeline_trace.txt"
  fields = 'task_id,hash,native_id,process,tag,name,status,exit,submit,start,complete,duration,realtime,cpus,memory,attempt'
  overwrite = true
}

report {
  enabled = true
  file = "${params.outdir}/pipeline_report.html"
  overwrite = true
}

timeline {
  enabled = true
  file = "${params.outdir}/pipeline_timeline.html"
  overwrite = true
}

dag {
  enabled = true
  file = "${params.outdir}/pipeline_dag.svg"
  overwrite = true
}
